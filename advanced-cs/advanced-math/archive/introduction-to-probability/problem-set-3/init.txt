>>>>>>>>>>>>>> joint probability 

P(A and B)  = P(A) *  P(B given A)
    event A happens with probability P(A)
    then event B happens given A happend 

if A and B are independent then

P(A and B) = P(A) * P(B)

example1(independent event)
its like if knowing that A happend doesn't change the probability of B

P(coinflip) = 1/2
P(rolladie) = 1/6 
P(coinflip and rolladie) = 1/2 * 1/6


example2(non independent event)
it rains today, the ground is wet 
P(ground is wet) = 0.2 = A
P(rains today) = 0.3 = B

P(A given B) - this is the key part, one is dependent on the other; 
                probability that the ground is wet given that it rained today
....

>>>>>>>>>>union probability 

P(A or B) 

P(A or B) = P(A) + P(B) - P(A and B)

example3

... this is clear for me, I dont need extra examples, I visualize a diagram



>>>>>>>>>conditional probability

P(A given B) = P(A and B)/P(B)


example4

P(A and B) = 1/6
P(B) = 1/3 

find P(A given B) 

P(A and B)/P(B) = 1/6/1/3 = 1/2



P(A given B) = [P(B given A) * P(A) ]/P(B) - Bayes' Theorem 

P(A) - prior probability of event A 
P(B given A) - likehood event 
P(B) - total probability of B, evidence 


practice problem1

a factory produces 1% defective items P(D) = 0.01
if product is defective, the test is positive with 99% probability P(Pos | D) = 0.99
if product not defective , test is positive with 5% probability P(Pos | not D) = 0.05

product is defective given the test is positive -

P(D given Pos) = [P(Pos given D) * P(D)]/P(Pos)

where - 

P(Pos) = P(Pos given D) * P(D) + P(Pos given not D) * P(not D)


Calculate P(Pos) then P(D given Pos)

P(Pos) = 0.99 * 0.01 + 0.05 * P(not D)
P(not D) = 1 - P(D) = 1 - 0.01 = 0.99 
P(Pos) = 0.99 * 0.01 + 0.05 * 0.99 = 0.0594

final anwer 
P(D given Pos) = 0.99 * 0.01 / 0.0594 equals around 16%


P(A) = Sigma(i=1,n) of P(A given Bi) * P(Bi) - law of total probability, (which essentially is joint non independent probability)
The law states that the total probability of an event A, is the sum of its probabilities in all possible scenarios, weighted by the probability of each scenario.


>>>>>>>>>>more explanation on conditional probability 
The law of total probability is useful because it allows us to compute the probability of an event A, 
by breaking it down into cases based on another event B.

A depends on B, which means P(A given B) is known 
we know the probability of different cases P(B) P(not B), but not P(A)
By using the law of total probability  P(A given B) P(A given not B), P(B) P(not B), to get the P(A),
this is like averaging the conditional probabilities, weighted by how likely each case is.
Once we have P(A), we can use Bayes' Theorem to find the reverse conditional probiablitites of P(B given A)


example5
B its raining P(B) = 0.3
A you carry an umbrella

if it rains you carry an umbrella with probability P(A given B) = 0.8
if it doesn't rain you carry an umbrella with probability P(A given not B) = 0.1 

What is the probability of A ? we want P(A)

using the law of total probability 

P(A) = P(A given B) * P(B) + P(A given not B) * P(not B) = 0.8 * 0.3 + 0.7 * 0.1 = 31%


summary/conclusion:
okay so I think I got it, my summary for contional probability is that, 
if some A depends on some B, then its impossible to predict the correct answer without knowing the whole tree